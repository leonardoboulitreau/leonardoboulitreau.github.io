---
permalink: /
title: me
layout: singlehome
author_profile: true
---
## I make machines that sing, speak, play, and hear.
I am a PhD in the intersection of audio and machine learning at the [Institute Polytechnique de Paris](https://www.ip-paris.fr/en) under the supervision of prof. [Gaël Richard](https://www.telecom-paris.fr/gael-richard?l=en), researching singing voice modeling. I have over five years of experience in the field and a background in signal processing. I am also a hobbyist music producer and guitarist.

## Interests
Development of audio‑based machines that are transparent and human‑empowering in topics such as: 
* Singing Voice & Speech
* (Differentiable) Digital Signal Processing
* Deep/Machine Learning

## Selected Works
  * Interspeech's SER Challenge (2025): [Improving Speech Emotion Recognition Through Cross Modal Attention Alignment and Balanced Stacking Model](https://arxiv.org/abs/2505.20007)
  * Master's Thesis (2024): [Cross-Speaker Style Transfer for TTS with Singing Voice Conversion Data Augmentation, Style Filtering, and F0 Matching](https://repositorio.unicamp.br/Busca/Download?codigoArquivo=585009&tipoMidia=0)
  * Interspeech's SynData4GenAI (2024): [Exploring synthetic data for cross-speaker style transfer in style representation based TTS](https://www.isca-archive.org/syndata4genai_2024/ueda24_syndata4genai.pdf)
  * GENEA (2023): [Gesture Generation with Diffusion Models Aided by Speech Activity Information](https://dl.acm.org/doi/pdf/10.1145/3610661.3616554)
