---
permalink: /
layout: singlehome
title: "I'm Leo!"
author_profile: true
---

**Welcome to my ðŸ’¿ (digital media where i store my audio(+AI) and portfolio content)!**

### I make machines that speak, sing, play, and hear.

 I am a researcher in the intersection of Artificial Intelligence and Audio, with a solid background in signal processing. Currently, I am a Junior Speech Researcher [@CPqD](https://www.linkedin.com/company/cpqd/) working with Automatic Speech Recognition (ASR) and speech age classification. I am also a hobbyist music producer, composer, and multiâ€‘instrumentalist.

## Interests
My research interests are aimed at developing audioâ€‘based humanâ€‘machine interaction systems that are more affective and humanâ€‘empowering in topics such as: 

* Text-to-Speech (TTS), Text-to-Audio (TTA)
* Automatic Speech Recognition (ASR), Speaker Diarization (SD)
* Voice Conversion (VC), Singing Voice Conversion (SVC)
* Speech Emotion, Age and Gender Recognition
* Music Generation/Classification, Neural Audio Effects

## Skills
  * **Deep Learning**: PyTorch, Tensorflow, Sci-Kit, HuggingFace, ONNX, Gradio
  * **Audio Frameworks**: Amphion, Coqui, SpeechBrain, ESPNET, NeMo
  * **Tools**: Docker, Git
  * **Programming**: Python, C, C++, MATLAB, LaTeX
  * **Cloud**: AWS, GCP
  * **Languages**: Portuguese, English, French
  * **Competences**: Paper Implementation, Experiment Design, Team Collaboration

## Work Experience
**(2023-Current) - Junior Speech Researcher [@CPqD](https://www.linkedin.com/company/cpqd/)**
  * Enriched the companyâ€™s call center customer profiling product by developing and sending to production speech age and gender classifier models.
  * Improved the companyâ€™s emotion recognition system in production, in terms of speed and performance, by developing a 2â€‘step emotion recognition architecture (ECAPAâ€‘TDNN to filter out neutral speech + WavLM Emotion Classifier).
    
**(2021-2023) - Fellow Master [@CPqD](https://www.linkedin.com/company/cpqd/)**
  * Developed neural customerâ€‘oriented expressive speech synthesis models for the Brazilian Portuguese language.
  * Enabled customers to edit the synthesized audiosâ€™ prosody in a fineâ€‘grained way by implementing characterâ€‘level prosody control graph
pipelines on the ONNX version of the FastPitch TTS model.
  * Conducted several subjective perceptual experiments to evaluate synthetic audio quality and naturalness.
    
**(2020-2021) - Lab Intern @LPS**
  * Enhanced lab automation by designing neural speech commands recognition systems.
  * Encapsulated the ASR system in a local private LoRa network for IoT purposes.
  * Enabled long distance voice control by developing a wearable prototype with an embedded microphone.
    
## Education
(2021-2024) M.Sc. Computer Engineering [@UNICAMP](https://www.unicamp.br/unicamp/) (#2 LATAM)

(2019-2020) Excellence Exchange Student [@TÃ©lÃ©com Paris](https://www.telecom-paris.fr/)

(2017-2021) B.Sc. Electronic Engineering [@UFPB](https://www.ufpb.br/)

