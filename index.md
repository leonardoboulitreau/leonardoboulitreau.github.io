---
permalink: /
layout: singlehome
title: "I'm Leo!"
author_profile: true
---
### I make machines that speak, sing, play, and hear.

I am a researcher in the intersection of AI and Audio, with a solid background in signal processing. Currently, I'm working with automatic speech recognition and speech age classification [@CPqD](https://www.linkedin.com/company/cpqd/). I am also a hobbyist music producer, composer, and multi‑instrumentalist.

## Interests
My research interests are aimed at developing audio‑based human‑machine interaction systems that are more affective and human‑empowering in topics such as: 

* Text-to-Speech (TTS), Text-to-Audio (TTA)
* Automatic Speech Recognition (ASR), Speaker Diarization (SD)
* Voice Conversion (VC), Singing Voice Conversion (SVC)
* Speech Emotion, Age and Gender Recognition
* Music Generation/Classification, Neural Audio Effects

## Skills
  * **Deep Learning**: PyTorch, Tensorflow, Sci-Kit, HuggingFace, ONNX, Gradio
  * **Speech Frameworks**: Amphion, Coqui, SpeechBrain, ESPNET, NeMo, Kaldi
  * **Tools**: Docker, Git, Cloud (AWS, GCP)
  * **Programming**: Python, C, C++, MATLAB, LaTeX
  * **Languages**: Portuguese, English, French
  * **Competences**: Paper Implementation, Experiment Design, Team Collaboration

## Work Experience
**(2023-Current) - AI+Speech Researcher [@CPqD](https://www.linkedin.com/company/cpqd/)**
  * Currently upgrading the company’s automatic speech recognition (ASR) system with external large language model fusion techniques and synthetic data.
  • Evaluated fairness on multi‑accented speech recognition for the Brazilian Portuguese language.
  • Improved the company’s emotion recognition system in production, in terms of speed and performance, by developing a 2‑step emotion recognition architecture (ECAPA‑TDNN + HuBERT Emotion Classifier)
  • Enriched the company’s call center customer profiling product by developing and sending to production speech age and gender classifier models.
    
**(2021-2023) - Fellow Master [@CPqD](https://www.linkedin.com/company/cpqd/)**
  * Developed neural customer‑oriented expressive speech synthesis models for the Brazilian Portuguese language.
  * Enabled customers to edit the synthesized audios’ prosody in a fine‑grained way by implementing character‑level prosody control on the ONNX version of the FastPitch TTS model.
  * Conducted several subjective perceptual experiments to evaluate synthetic audio quality, naturalness and expresiveness.
    
**(2020-2021) - Lab Intern @LPS**
  * Enhanced lab automation by designing a neural speech commands recognition system.
  * Encapsulated an ASR system in a local private LoRa network for IoT purposes.
  * Enabled long distance voice control by developing a wearable prototype with an embedded microphone.
    
## Education
(2021-2024) M.Sc. Computer Engineering [@UNICAMP](https://www.unicamp.br/unicamp/) (#2 Latin America)

(2019-2020) Excellence Scolarship Exchange Student [@Télécom Paris](https://www.telecom-paris.fr/)

(2017-2021) B.Sc. Electronic Engineering [@UFPB](https://www.ufpb.br/)

